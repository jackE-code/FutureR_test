{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d434c64e",
   "metadata": {},
   "source": [
    "# Dataset:\n",
    "You will be working with two datasets: Train and Test, both containing images of 40 individuals. Each dataset has been preprocessed for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5a47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb82dc",
   "metadata": {},
   "source": [
    "# Create PCA function that takes two inputs: dataset, and k= number of principle component, and return the transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6edc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pca(Data,k):\n",
    "    \"Build this function\"\n",
    "    # Calculate the mean of the data\n",
    "    mean = np.mean(Data, axis=0)\n",
    "    \n",
    "    # Center the data by subtracting the mean\n",
    "    centered_data = Data - mean\n",
    "    \n",
    "    # Compute the covariance matrix of the centered data\n",
    "    covariance_matrix = np.cov(centered_data, rowvar=False)\n",
    "    \n",
    "    # Perform eigendecomposition of the covariance matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    \n",
    "    # Sort the eigenvalues and eigenvectors in descending order\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[sorted_indices]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    \n",
    "    # Take the top k eigenvectors\n",
    "    top_k_eigenvectors = eigenvectors[:, :k]\n",
    "    \n",
    "    # Project the centered data onto the top k eigenvectors to get the transformed data\n",
    "    transformed_data = np.dot(centered_data, top_k_eigenvectors)\n",
    "    \n",
    "    return transformed_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e39036",
   "metadata": {},
   "source": [
    "# Read your TrainData and Test data. Try to remove the last column of the training data and assign it to one variable, do same thing for the TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9be5817a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original TrainData:\n",
      "     T_1  T_2  T_3  T_4  T_5  T_6  T_7  T_8  T_9  T_10  ...  T_10296  T_10297  \\\n",
      "0     48   51   43   44   56   50   39   46   57    50  ...       39       41   \n",
      "1     59   66   64   52   44   50   59   64   70    70  ...       30       30   \n",
      "2     40   40   54   47   56   35   69   43   37    37  ...       31       32   \n",
      "3     62   52   34   43   31   36   27   34   35    45  ...      170      165   \n",
      "4     62   74   71   51   44   57   69   69   63    52  ...       30       32   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...      ...      ...   \n",
      "195  103  104  106  107  107  106  104  103  105   109  ...       68       70   \n",
      "196  104  106  107  106  104  104  106  108  110   110  ...       65       65   \n",
      "197   98  104  110  111  107  105  107  110  109   107  ...       74       73   \n",
      "198  115  110  110  113  115  112  111  114  110   111  ...       92       96   \n",
      "199  109  109  110  110  111  112  112  113  114   114  ...       91      100   \n",
      "\n",
      "     T_10298  T_10299  T_10300  T_10301  T_10302  T_10303  T_10304  T_10305  \n",
      "0         43       46       47       48       47       47       47        1  \n",
      "1         31       32       32       35       35       34       34        1  \n",
      "2         31       30       31       30       30       29       28        1  \n",
      "3        159      162      168      141       37        8       27        1  \n",
      "4         34       34       34       37       38       38       39        1  \n",
      "..       ...      ...      ...      ...      ...      ...      ...      ...  \n",
      "195       70       69       74       65       66       68       71       40  \n",
      "196       65       66       66       68       70       68       62       40  \n",
      "197       75       74       65       76       74       71       71       40  \n",
      "198       90       85       92       86       87       88       89       40  \n",
      "199       92       85       97      100       93       88       90       40  \n",
      "\n",
      "[200 rows x 10305 columns]\n",
      "\n",
      "Original TestData:\n",
      "     T_1  T_2  T_3  T_4  T_5  T_6  T_7  T_8  T_9  T_10  ...  T_10296  T_10297  \\\n",
      "0     35   33   35   38   37   35   39   46   58    62  ...       42       40   \n",
      "1     44   52   32   62   80   85   64   53   45    47  ...      166      164   \n",
      "2     39   47   46   44   50   51   51   56   59    46  ...       36       34   \n",
      "3     45   44   38   31   30   35   39   39   48    60  ...       45       42   \n",
      "4     42   40   42   47   46   41   38   40   29    40  ...       37       37   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...      ...      ...   \n",
      "195  111  109  108  110  113  114  112  109  112   112  ...       93       90   \n",
      "196  114  114  114  114  114  114  114  114  115   113  ...       88       85   \n",
      "197  112  113  113  113  112  112  114  115  114   114  ...       90       91   \n",
      "198  112  112  112  111  112  112  113  114  110   110  ...       82       88   \n",
      "199  111  111  111  110  111  111  112  113  115   114  ...       95       93   \n",
      "\n",
      "     T_10298  T_10299  T_10300  T_10301  T_10302  T_10303  T_10304  Label  \n",
      "0         32       29       32       38       38       37       36      1  \n",
      "1        161      158      155      156      157      147      173      1  \n",
      "2         35       35       33       36       36       36       37      1  \n",
      "3         34       30       31       41       41       40       39      1  \n",
      "4         40       41       40       44       43       43       42      1  \n",
      "..       ...      ...      ...      ...      ...      ...      ...    ...  \n",
      "195       85       86       91       85       85       85       86     40  \n",
      "196       87       89       88       90       89       88       87     40  \n",
      "197       87       86       89       87       87       88       90     40  \n",
      "198       86       81       84       77       83       89       93     40  \n",
      "199       84       83       89       87       88       89       90     40  \n",
      "\n",
      "[200 rows x 10305 columns]\n",
      "\n",
      "Modified TrainData:\n",
      "     T_1  T_2  T_3  T_4  T_5  T_6  T_7  T_8  T_9  T_10  ...  T_10295  T_10296  \\\n",
      "0     48   51   43   44   56   50   39   46   57    50  ...       39       39   \n",
      "1     59   66   64   52   44   50   59   64   70    70  ...       32       30   \n",
      "2     40   40   54   47   56   35   69   43   37    37  ...       30       31   \n",
      "3     62   52   34   43   31   36   27   34   35    45  ...      174      170   \n",
      "4     62   74   71   51   44   57   69   69   63    52  ...       29       30   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...      ...      ...   \n",
      "195  103  104  106  107  107  106  104  103  105   109  ...       74       68   \n",
      "196  104  106  107  106  104  104  106  108  110   110  ...       66       65   \n",
      "197   98  104  110  111  107  105  107  110  109   107  ...       71       74   \n",
      "198  115  110  110  113  115  112  111  114  110   111  ...       91       92   \n",
      "199  109  109  110  110  111  112  112  113  114   114  ...       89       91   \n",
      "\n",
      "     T_10297  T_10298  T_10299  T_10300  T_10301  T_10302  T_10303  T_10304  \n",
      "0         41       43       46       47       48       47       47       47  \n",
      "1         30       31       32       32       35       35       34       34  \n",
      "2         32       31       30       31       30       30       29       28  \n",
      "3        165      159      162      168      141       37        8       27  \n",
      "4         32       34       34       34       37       38       38       39  \n",
      "..       ...      ...      ...      ...      ...      ...      ...      ...  \n",
      "195       70       70       69       74       65       66       68       71  \n",
      "196       65       65       66       66       68       70       68       62  \n",
      "197       73       75       74       65       76       74       71       71  \n",
      "198       96       90       85       92       86       87       88       89  \n",
      "199      100       92       85       97      100       93       88       90  \n",
      "\n",
      "[200 rows x 10304 columns]\n",
      "\n",
      "Last Column of TrainData:\n",
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "195    40\n",
      "196    40\n",
      "197    40\n",
      "198    40\n",
      "199    40\n",
      "Name: T_10305, Length: 200, dtype: int64\n",
      "\n",
      "Modified TestData:\n",
      "     T_1  T_2  T_3  T_4  T_5  T_6  T_7  T_8  T_9  T_10  ...  T_10295  T_10296  \\\n",
      "0     35   33   35   38   37   35   39   46   58    62  ...       37       42   \n",
      "1     44   52   32   62   80   85   64   53   45    47  ...      167      166   \n",
      "2     39   47   46   44   50   51   51   56   59    46  ...       26       36   \n",
      "3     45   44   38   31   30   35   39   39   48    60  ...       43       45   \n",
      "4     42   40   42   47   46   41   38   40   29    40  ...       39       37   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...      ...      ...   \n",
      "195  111  109  108  110  113  114  112  109  112   112  ...       91       93   \n",
      "196  114  114  114  114  114  114  114  114  115   113  ...       94       88   \n",
      "197  112  113  113  113  112  112  114  115  114   114  ...       86       90   \n",
      "198  112  112  112  111  112  112  113  114  110   110  ...       83       82   \n",
      "199  111  111  111  110  111  111  112  113  115   114  ...       90       95   \n",
      "\n",
      "     T_10297  T_10298  T_10299  T_10300  T_10301  T_10302  T_10303  T_10304  \n",
      "0         40       32       29       32       38       38       37       36  \n",
      "1        164      161      158      155      156      157      147      173  \n",
      "2         34       35       35       33       36       36       36       37  \n",
      "3         42       34       30       31       41       41       40       39  \n",
      "4         37       40       41       40       44       43       43       42  \n",
      "..       ...      ...      ...      ...      ...      ...      ...      ...  \n",
      "195       90       85       86       91       85       85       85       86  \n",
      "196       85       87       89       88       90       89       88       87  \n",
      "197       91       87       86       89       87       87       88       90  \n",
      "198       88       86       81       84       77       83       89       93  \n",
      "199       93       84       83       89       87       88       89       90  \n",
      "\n",
      "[200 rows x 10304 columns]\n",
      "\n",
      "Last Column of TestData:\n",
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "195    40\n",
      "196    40\n",
      "197    40\n",
      "198    40\n",
      "199    40\n",
      "Name: Label, Length: 200, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# write the code here\n",
    "\n",
    "# Read TrainData and TestData\n",
    "train_data = pd.read_csv('TrainData.csv')\n",
    "test_data = pd.read_csv('TestData.csv')\n",
    "\n",
    "# Display the original datasets\n",
    "print(\"Original TrainData:\")\n",
    "print(train_data)\n",
    "\n",
    "print(\"\\nOriginal TestData:\")\n",
    "print(test_data)\n",
    "\n",
    "# Remove the last column from TrainData and TestData and assign it to variables\n",
    "last_column_train = train_data.iloc[:, -1]  # assuming iloc is used for position based indexing\n",
    "train_data = train_data.iloc[:, :-1]\n",
    "\n",
    "last_column_test = test_data.iloc[:, -1]\n",
    "test_data = test_data.iloc[:, :-1]\n",
    "\n",
    "# Display the modified datasets\n",
    "print(\"\\nModified TrainData:\")\n",
    "print(train_data)\n",
    "\n",
    "print(\"\\nLast Column of TrainData:\")\n",
    "print(last_column_train)\n",
    "\n",
    "print(\"\\nModified TestData:\")\n",
    "print(test_data)\n",
    "\n",
    "print(\"\\nLast Column of TestData:\")\n",
    "print(last_column_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d8316d",
   "metadata": {},
   "source": [
    "# Apply my_pca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d1ef819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (201, 10304)\n",
      "Transformed data shape: (201, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load TrainData.csv\n",
    "train_data = np.genfromtxt('TrainData.csv', delimiter=',')\n",
    "\n",
    "# Extract features (assuming the features are in columns 1 to second-to-last column)\n",
    "features = train_data[:, :-1]\n",
    "\n",
    "# Apply PCA with k=10 (you can adjust k as needed)\n",
    "transformed_data = my_pca(features, k=10)\n",
    "\n",
    "# Display the shape of the transformed data\n",
    "print(f\"Original data shape: {features.shape}\")\n",
    "print(f\"Transformed data shape: {transformed_data.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f4effc",
   "metadata": {},
   "source": [
    "# Apply pca using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c0e7685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (200, 10304)\n",
      "Transformed data shape: (200, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load TrainData.csv\n",
    "train_data = pd.read_csv('TrainData.csv')\n",
    "\n",
    "# Extract features (assuming the features are in columns 1 to second-to-last column)\n",
    "features = train_data.iloc[:, :-1].values\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "standardized_features = scaler.fit_transform(features)\n",
    "\n",
    "# Apply PCA with the desired number of components (k)\n",
    "num_components = 10  # Set the desired number of principal components\n",
    "pca = PCA(n_components=num_components)\n",
    "transformed_data = pca.fit_transform(standardized_features)\n",
    "\n",
    "# Display the shape of the transformed data\n",
    "print(f\"Original data shape: {features.shape}\")\n",
    "print(f\"Transformed data shape: {transformed_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8310d07d",
   "metadata": {},
   "source": [
    "# Create kernel PCA function that takes two inputs: dataset, and k= number of principle component, and return the transform data. In addition, you need to create three other function one for rbf_kernel, one for polynomial_kernel, and one for linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c19afe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rbf_kernel(x, y, gamma=1.0):\n",
    "    \"\"\"\n",
    "    Radial Basis Function (RBF) kernel.\n",
    "    \"\"\"\n",
    "    return np.exp(-gamma * np.linalg.norm(x - y) ** 2)\n",
    "\n",
    "def poly_kernel(x, y, degree=3):\n",
    "    \"\"\"\n",
    "    Polynomial kernel.\n",
    "    \"\"\"\n",
    "    return (np.dot(x, y) + 1) ** degree\n",
    "\n",
    "def linear_kernel(x, y):\n",
    "    \"\"\"\n",
    "    Linear kernel.\n",
    "    \"\"\"\n",
    "    return np.dot(x, y)\n",
    "\n",
    "def my_kpca(data, n_components, kernel_type='rbf', kernel_param=1.0):\n",
    "    \"\"\"\n",
    "    Kernel Principal Component Analysis (KPCA) function.\n",
    "\n",
    "    Parameters:\n",
    "    - data: Input data as an ndarray of shape (n_samples, n_features).\n",
    "    - n_components: Number of principal components to retain.\n",
    "    - kernel_type: Type of kernel ('rbf', 'poly', or 'linear').\n",
    "    - kernel_param: Kernel parameter (e.g., gamma for RBF, degree for polynomial).\n",
    "\n",
    "    Returns:\n",
    "    - Transformed data in the KPCA space.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_samples = data.shape[0]\n",
    "    kernel_matrix = np.zeros((n_samples, n_samples))\n",
    "\n",
    "    # Build the kernel matrix based on the specified kernel type\n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_samples):\n",
    "            if kernel_type == 'rbf':\n",
    "                kernel_matrix[i, j] = rbf_kernel(data[i], data[j], gamma=kernel_param)\n",
    "            elif kernel_type == 'poly':\n",
    "                kernel_matrix[i, j] = poly_kernel(data[i], data[j], degree=kernel_param)\n",
    "            elif kernel_type == 'linear':\n",
    "                kernel_matrix[i, j] = linear_kernel(data[i], data[j])\n",
    "            else:\n",
    "                raise ValueError(\"Invalid kernel type. Supported types are 'rbf', 'poly', and 'linear'.\")\n",
    "\n",
    "    # Center the kernel matrix\n",
    "    one_n = np.ones((n_samples, n_samples)) / n_samples\n",
    "    centered_matrix = kernel_matrix - one_n.dot(kernel_matrix) - kernel_matrix.dot(one_n) + one_n.dot(kernel_matrix).dot(one_n)\n",
    "\n",
    "    # Eigendecomposition\n",
    "    eigvals, eigvecs = np.linalg.eigh(centered_matrix)\n",
    "    eigvecs = eigvecs[:, ::-1]\n",
    "\n",
    "    # Select the top n_components eigenvectors\n",
    "    indices = np.argsort(eigvals)[::-1][:n_components]\n",
    "    eigvals, eigvecs = eigvals[indices], eigvecs[:, indices]\n",
    "\n",
    "    # Normalize eigenvectors by eigenvalues\n",
    "    eigvecs = eigvecs / np.sqrt(eigvals)\n",
    "\n",
    "    # Project the data onto the eigenvectors\n",
    "    transformed_data = np.dot(centered_matrix, eigvecs)\n",
    "\n",
    "    return transformed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e287808",
   "metadata": {},
   "source": [
    "# Apply my_kpca on the Train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4180ca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (201, 10304)\n",
      "Transformed data shape: (201, 10)\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already defined the my_kpca function and the kernel functions (rbf_kernel, poly_kernel, linear_kernel)\n",
    "\n",
    "# Load TrainData.csv\n",
    "train_data = np.genfromtxt('TrainData.csv', delimiter=',')\n",
    "\n",
    "# Extract features (assuming the features are in columns 1 to second-to-last column)\n",
    "features = train_data[:, :-1]\n",
    "\n",
    "# Apply KPCA with, for example, k=10 using the RBF kernel\n",
    "k = 10\n",
    "transformed_data = my_kpca(features, n_components=k, kernel_type='rbf', kernel_param=1.0)\n",
    "\n",
    "# Display the shape of the transformed data\n",
    "print(f\"Original data shape: {features.shape}\")\n",
    "print(f\"Transformed data shape: {transformed_data.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06316d0",
   "metadata": {},
   "source": [
    "# Apply Kpca using sklearn on Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a63724c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (201, 10304)\n",
      "Transformed data shape: (201, 5)\n"
     ]
    }
   ],
   "source": [
    "# build your code here\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Load TrainData.csv\n",
    "train_data = np.genfromtxt('TrainData.csv', delimiter=',')\n",
    "\n",
    "# Extract features (assuming the features are in columns 1 to second-to-last column)\n",
    "features = train_data[:, :-1]\n",
    "\n",
    "# Handle missing values (replace NaN with the mean value)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "# Flatten each image into a one-dimensional array\n",
    "flattened_images = features_imputed.reshape(features_imputed.shape[0], -1)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(flattened_images)\n",
    "\n",
    "# Apply Kernel PCA with RBF kernel\n",
    "kpca = KernelPCA(n_components=5, kernel='rbf', gamma=1.0)\n",
    "transformed_data = kpca.fit_transform(features_standardized)\n",
    "\n",
    "# Display the shape of the transformed data\n",
    "print(f\"Original data shape: {flattened_images.shape}\")\n",
    "print(f\"Transformed data shape: {transformed_data.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc14d4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e956f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb830358",
   "metadata": {},
   "source": [
    "# You can use the functions below as your classifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0b009f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate distance between two points\n",
    "def dis(x1, x2):\n",
    "    return np.linalg.norm(x1 - x2)\n",
    "\n",
    "# Function to perform classification \n",
    "def myclassifier(Train, Trainlabel, Test):\n",
    "    \" Train is the training data\"\n",
    "    \" Trainlabel is the training labels\"\n",
    "    \" Test is the testing data\"\n",
    "    pred = []\n",
    "\n",
    "    for testpoint in Test:\n",
    "        pred_dis = []\n",
    "        for trainpoint in Train:\n",
    "            pred_dis.append(dis(testpoint, trainpoint))\n",
    "\n",
    "        pred.append(np.argmin(pred_dis))  \n",
    "\n",
    "    return np.array(pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62885a8f",
   "metadata": {},
   "source": [
    "# Below function is to calculte the accuracy , you can use this function to get the accuracy of pca and kpca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25b0c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(true_labels, predicted_labels):\n",
    "    # Ensure that the true labels and predicted labels have the same length\n",
    "    if len(true_labels) != len(predicted_labels):\n",
    "        raise ValueError(\"Length of true_labels and predicted_labels must be the same.\")\n",
    "\n",
    "    # Count the number of correct predictions\n",
    "    correct_predictions = sum(1 for true, predicted in zip(true_labels, predicted_labels) if true == predicted)\n",
    "\n",
    "    # Calculate accuracy as the ratio of correct predictions to total predictions\n",
    "    accuracy = correct_predictions / len(true_labels)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a648d942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KPCA Accuracy: 0.04878048780487805\n",
      "PCA Accuracy: 0.04878048780487805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load TrainData.csv\n",
    "train_data = np.genfromtxt('TrainData.csv', delimiter=',')\n",
    "\n",
    "# Extract features (assuming the features are in columns 1 to second-to-last column)\n",
    "features = train_data[:, :-1]\n",
    "\n",
    "# Extract labels (assuming labels are in the last column)\n",
    "labels = train_data[:, -1]\n",
    "\n",
    "# Handle missing values (replace NaN with the mean value)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "# Flatten each image into a one-dimensional array\n",
    "flattened_images = features_imputed.reshape(features_imputed.shape[0], -1)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(flattened_images)\n",
    "\n",
    "# Apply Kernel PCA with RBF kernel\n",
    "kpca = KernelPCA(n_components=10, kernel='rbf', gamma=1.0)\n",
    "transformed_data = kpca.fit_transform(features_standardized)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use your classifier (myclassifier) on the transformed data\n",
    "kpca_predictions = myclassifier(X_train, y_train, X_test)\n",
    "\n",
    "# Calculate accuracy using your provided 'calculate_accuracy' function\n",
    "kpca_accuracy = calculate_accuracy(y_test, kpca_predictions)\n",
    "\n",
    "print(\"KPCA Accuracy:\", kpca_accuracy)\n",
    "# Use your classifier (myclassifier) on the transformed data\n",
    "pca_predictions = myclassifier(X_train, y_train, X_test)\n",
    "\n",
    "# Calculate accuracy using your provided 'calculate_accuracy' function\n",
    "pca_accuracy = calculate_accuracy(y_test, pca_predictions)\n",
    "\n",
    "print(\"PCA Accuracy:\", pca_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae7d044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9417279d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5456cdb0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a4eec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
